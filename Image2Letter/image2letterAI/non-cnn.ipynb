{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/repositories/Typewriter/Image2Letter/.venv/lib64/python3.11/site-packages/pydantic/_internal/_fields.py:127: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/peter/repositories/Typewriter/Image2Letter/.venv/lib64/python3.11/site-packages/pydantic/_internal/_config.py:269: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from utils import  get_sobel_kernel, get_gaussian_kernel, load_letter_conv_weights, get_rel_area_letters\n",
    "from models import CustomTransposedConv2d\n",
    "\n",
    "class LetterFilter(pl.LightningModule):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.device = config[\"device\"]\n",
    "        self.letter_conv_k = config[\"letter_conv_k\"]\n",
    "        self.letter_conv_stride = config[\"letter_conv_stride\"]\n",
    "        sobel_k = config[\"sobel_k\"]\n",
    "        gauss_sig = config[\"gauss_sig\"]\n",
    "        font_path = config[\"font_path\"]\n",
    "        letters = config[\"letters\"]\n",
    "        self.num_letters = len(letters)\n",
    "        self.letters_per_pix = config[\"letters_per_pix\"]\n",
    "        gauss_k = self.letter_conv_k\n",
    "        self.eps = config[\"eps\"]\n",
    "\n",
    "        self.letter_size_alpha = config[\"letter_size_weight\"]\n",
    "        self.detail_beta = config[\"detail_weight\"]\n",
    "\n",
    "        # sobel edge filter\n",
    "        sobel_2D = get_sobel_kernel(sobel_k)\n",
    "        self.sobel_filter_x = nn.Conv2d(in_channels=1,\n",
    "                                        out_channels=1,\n",
    "                                        kernel_size=sobel_k,\n",
    "                                        padding=sobel_k // 2,\n",
    "                                        bias=False)\n",
    "        self.sobel_filter_x.weight[:] = torch.from_numpy(sobel_2D)\n",
    "\n",
    "\n",
    "        self.sobel_filter_y = nn.Conv2d(in_channels=1,\n",
    "                                        out_channels=1,\n",
    "                                        kernel_size=sobel_k,\n",
    "                                        padding=sobel_k // 2,\n",
    "                                        bias=False)\n",
    "        self.sobel_filter_y.weight[:] = torch.from_numpy(sobel_2D.T)\n",
    "\n",
    "        #gaussian fitler after sobel\n",
    "        gaussian_2D = get_gaussian_kernel(gauss_k, 0, gauss_sig)\n",
    "        self.gaussian_filter = nn.Conv2d(in_channels=1,\n",
    "                                         out_channels=1,\n",
    "                                         kernel_size=gauss_k,\n",
    "                                         stride=self.letter_conv_stride,\n",
    "                                         padding=gauss_k // 2,\n",
    "                                         bias=False)\n",
    "        self.gaussian_filter.weight[:] = torch.from_numpy(gaussian_2D)\n",
    "\n",
    "        # letter convolutions\n",
    "        letter_conv_weights = load_letter_conv_weights(font_path, self.letter_conv_k, letters)\n",
    "        self.letter_filter = nn.Conv2d(in_channels=1,\n",
    "                                       out_channels=1,\n",
    "                                       kernel_size=self.letter_conv_k,\n",
    "                                       stride=self.letter_conv_stride,\n",
    "                                       padding=self.letter_conv_k//2)\n",
    "        self.letter_filter.weight[:] = letter_conv_weights\n",
    "\n",
    "        # letter areas\n",
    "        self.letter_conv_areas = get_rel_area_letters(font_path, self.letter_conv_k, letters)\n",
    "\n",
    "\n",
    "        # transposed convs for mask\n",
    "        transposed_convs_weights = load_letter_conv_weights(font_path, self.letter_conv_k, letters)\n",
    "        transposed_padding = self.letter_conv_k // 2\n",
    "        transpose_out_padding = self.letter_conv_stride -1 \n",
    "        self.transp_conv = CustomTransposedConv2d(transposed_convs_weights,\n",
    "                                                   self.num_letters,\n",
    "                                                     1,\n",
    "                                                       self.letter_conv_k,\n",
    "                                                         self.letter_conv_stride,\n",
    "                                                           transposed_padding,\n",
    "                                                             transpose_out_padding)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_img: torch.Tensor):\n",
    "        B, _, H, W = input_img.shape # C will be 1\n",
    "        H_letter_hits = (H - self.letter_conv_k + 2 * self.letter_conv_k//2) // self.letter_conv_stride + 1\n",
    "        W_letter_hits = (W - self.letter_conv_k + 2 * self.letter_conv_k//2) // self.letter_conv_stride + 1\n",
    "        max_letter_hits_total = B * H_letter_hits * W_letter_hits \n",
    "        grad_x = torch.zeros((B, 1, H, W)).to(self.device)\n",
    "        grad_y = torch.zeros((B, 1, H, W)).to(self.device)\n",
    "        grad_magnitude = torch.zeros((B, 1, H, W)).to(self.device)\n",
    "        detail_map = torch.zeros((B, 1, H_letter_hits, W_letter_hits)).to(self.device)\n",
    "        letter_hits = torch.zeros((B, self.num_letters, H_letter_hits, W_letter_hits)).to(self.device)\n",
    "        # tracks letter hits pixels with max letter per pix reached, 0 = max reached\n",
    "        filled_pixels = torch.ones((B, 1, H_letter_hits, W_letter_hits)).to(self.device)\n",
    "\n",
    "        letter_match = torch.zeros((B, self.num_letters, H_letter_hits, W_letter_hits)).to(self.device)\n",
    "        letter_areas = torch.zeros((B, self.num_letters, H_letter_hits, W_letter_hits)).to(self.device)        \n",
    "        current_img = input_img.clone()\n",
    "\n",
    "        # grad\n",
    "        grad_x = self.sobel_filter_x(input_img)\n",
    "        grad_y = self.sobel_filter_y(input_img)\n",
    "        grad_magnitude = (grad_x ** 2 + grad_y ** 2) ** 0.5\n",
    "        # normalize to [0,1]\n",
    "        grad_max = grad_magnitude.max()\n",
    "        grad_magnitude = grad_magnitude / grad_max if grad_max > 0 else grad_magnitude\n",
    "\n",
    "        # blurr gradient image\n",
    "        detail_map = self.gaussian_filter(grad_magnitude)\n",
    "        # normalize to [0,1]\n",
    "        grad_blurr_max = detail_map.max()\n",
    "        detail_map = detail_map / grad_blurr_max if grad_blurr_max > 0 else detail_map\n",
    "\n",
    "        # letter areas\n",
    "        letter_areas = self.letter_conv_areas.view(1, self.num_letters, 1, 1).expand(B, self.num_letters, H_letter_hits, W_letter_hits)\n",
    "\n",
    "        # letter matches\n",
    "        letter_match : torch.Tensor = self.letter_filter(current_img)\n",
    "        # letter hits total\n",
    "        letter_hits_total = torch.sum(letter_hits == 0)\n",
    "\n",
    "        while torch.any(letter_match > self.eps) and letter_hits_total < max_letter_hits_total:\n",
    "            # TODO work on this line\n",
    "            weighted_letter_match = letter_match.mul(torch.abs(self.letter_size_alpha *letter_areas - self.detail_beta * detail_map))\n",
    "            indices = torch.argmax(weighted_letter_match.view(B, -1), dim=1, keepdim=True)\n",
    "            mask = torch.zeros_like(weighted_letter_match.view(B, -1))\n",
    "            mask = mask.scatter(1, indices, 1)\n",
    "            mask = mask.view(B, self.num_letters, H_letter_hits, W_letter_hits)\n",
    "            # add max letter hit of image of current iteration to all letterhits\n",
    "            letter_hits = letter_hits + mask.mul(letter_match)\n",
    "\n",
    "            # set filled pixels to 0 in filled pixels mask\n",
    "            filled_pixels = (letter_hits > 0).sum(dim=1, keepdim=True) < self.letters_per_pix\n",
    "\n",
    "            # update current image: substract found best letter from input img\n",
    "            current_img = torch.clip(input_img - self.transp_conv(letter_hits), torch.tensor(0.), torch.tensor(1.))\n",
    "\n",
    "            # letter matches\n",
    "            letter_match = self.letter_filter(current_img)\n",
    "            # set pixel with reached max letters per pix to zero\n",
    "            letter_match = letter_match.mul(filled_pixels)\n",
    "\n",
    "            # letter hits total\n",
    "            letter_hits_total = torch.sum(filled_pixels == 0)\n",
    "        \n",
    "        return letter_hits, self.transp_conv(letter_hits).clip(torch.tensor(0.), torch.tensor(1.))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

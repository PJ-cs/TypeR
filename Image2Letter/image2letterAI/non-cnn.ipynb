{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from utils import  get_sobel_kernel, get_gaussian_kernel, load_letter_conv_weights, get_rel_area_letters\n",
    "from models import CustomTransposedConv2d\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "class LetterFilter(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.device = config[\"device\"]\n",
    "        self.letter_conv_k = config[\"letter_conv_k\"]\n",
    "        self.letter_conv_stride = config[\"letter_conv_stride\"]\n",
    "        sobel_k = config[\"sobel_k\"]\n",
    "        gauss_sig = config[\"gauss_sig\"]\n",
    "        font_path = config[\"font_path\"]\n",
    "        letters = config[\"letters\"]\n",
    "        self.num_letters = len(letters)\n",
    "        self.letters_per_pix = config[\"letters_per_pix\"]\n",
    "        gauss_k = self.letter_conv_k\n",
    "        self.eps = config[\"eps\"]\n",
    "\n",
    "        self.letter_size_alpha = config[\"letter_size_weight\"]\n",
    "        self.detail_beta = config[\"detail_weight\"]\n",
    "        self.overlap_gamma = config[\"overlap_gamma\"]\n",
    "\n",
    "        # sobel edge filter\n",
    "        # https://towardsdatascience.com/implement-canny-edge-detection-from-scratch-with-pytorch-a1cccfa58bed\n",
    "        with torch.no_grad():\n",
    "          sobel_2D = get_sobel_kernel(sobel_k)\n",
    "          self.sobel_filter_x = nn.Conv2d(in_channels=1,\n",
    "                                          out_channels=1,\n",
    "                                          kernel_size=sobel_k,\n",
    "                                          padding=sobel_k //2,\n",
    "                                          bias=False)\n",
    "          self.sobel_filter_x.weight[:] = torch.from_numpy(sobel_2D)\n",
    "\n",
    "\n",
    "          self.sobel_filter_y = nn.Conv2d(in_channels=1,\n",
    "                                          out_channels=1,\n",
    "                                          kernel_size=sobel_k,\n",
    "                                          padding=sobel_k //2,\n",
    "                                          bias=False)\n",
    "          self.sobel_filter_y.weight[:] = torch.from_numpy(sobel_2D.T)\n",
    "\n",
    "          #gaussian fitler after sobel\n",
    "          gaussian_2D = get_gaussian_kernel(gauss_k, 0, gauss_sig)\n",
    "          self.gaussian_filter = nn.Conv2d(in_channels=1,\n",
    "                                          out_channels=1,\n",
    "                                          kernel_size=gauss_k,\n",
    "                                          stride=self.letter_conv_stride,\n",
    "                                          bias=False)\n",
    "          self.gaussian_filter.weight[:] = torch.from_numpy(gaussian_2D)\n",
    "\n",
    "          # letter convolutions\n",
    "          letter_conv_weights = load_letter_conv_weights(font_path, self.letter_conv_k, letters)\n",
    "          self.letter_filter = nn.Conv2d(in_channels=1,\n",
    "                                        out_channels=self.num_letters,\n",
    "                                        kernel_size=self.letter_conv_k,\n",
    "                                        stride=self.letter_conv_stride)\n",
    "          self.letter_filter.weight[:] = letter_conv_weights\n",
    "\n",
    "          # letter areas\n",
    "          self.letter_conv_areas = get_rel_area_letters(font_path, self.letter_conv_k, letters)\n",
    "\n",
    "\n",
    "          # transposed convs for mask\n",
    "          transposed_convs_weights = load_letter_conv_weights(font_path, self.letter_conv_k, letters)\n",
    "          transposed_padding = 0\n",
    "          transpose_out_padding = self.letter_conv_stride -1 \n",
    "          self.transp_conv = CustomTransposedConv2d(transposed_convs_weights,\n",
    "                                                    self.num_letters,\n",
    "                                                      1,\n",
    "                                                        self.letter_conv_k,\n",
    "                                                          self.letter_conv_stride,\n",
    "                                                            transposed_padding,\n",
    "                                                              transpose_out_padding)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_img: torch.Tensor):\n",
    "        B, _, H, W = input_img.shape # C will be 1\n",
    "        \n",
    "        # pad input image\n",
    "        input_img = nn.ReplicationPad2d(self.letter_conv_k//2)(input_img)\n",
    "\n",
    "        _, _, H_letter_hits, W_letter_hits = self.gaussian_filter(torch.randn_like(input_img)).shape\n",
    "\n",
    "        max_letter_hits_total = B * H_letter_hits * W_letter_hits\n",
    "        grad_x = torch.zeros((B, 1, H, W)).to(self.device)\n",
    "        grad_y = torch.zeros((B, 1, H, W)).to(self.device)\n",
    "        grad_magnitude = torch.zeros((B, 1, H, W)).to(self.device)\n",
    "        detail_map = torch.zeros((B, 1, H_letter_hits, W_letter_hits)).to(self.device)\n",
    "        letter_hits = torch.zeros((B, self.num_letters, H_letter_hits, W_letter_hits)).to(self.device)\n",
    "        # tracks letter hits pixels with max letter per pix reached, 0 = max reached\n",
    "        filled_pixels = torch.ones((B, 1, H_letter_hits, W_letter_hits)).to(self.device)\n",
    "\n",
    "        letter_match = torch.zeros((B, self.num_letters, H_letter_hits, W_letter_hits)).to(self.device)\n",
    "        letter_areas = torch.zeros((B, self.num_letters, H_letter_hits, W_letter_hits)).to(self.device)        \n",
    "        current_img = input_img.clone()\n",
    "\n",
    "        # grad\n",
    "        grad_x = self.sobel_filter_x(input_img)\n",
    "        grad_y = self.sobel_filter_y(input_img)\n",
    "        grad_magnitude = (grad_x ** 2 + grad_y ** 2) ** 0.5\n",
    "        # normalize to [0,1]\n",
    "        grad_max = grad_magnitude.max()\n",
    "        grad_magnitude = grad_magnitude / grad_max if grad_max > 0 else grad_magnitude\n",
    "\n",
    "        # blurr gradient image\n",
    "        detail_map = self.gaussian_filter(grad_magnitude)\n",
    "        # normalize to [0,1]\n",
    "        grad_blurr_max = detail_map.max()\n",
    "        detail_map = detail_map / grad_blurr_max if grad_blurr_max > 0 else detail_map\n",
    "\n",
    "\n",
    "        # letter areas\n",
    "        letter_areas = self.letter_conv_areas.view(1, self.num_letters, 1, 1).expand(B, self.num_letters, H_letter_hits, W_letter_hits)\n",
    "\n",
    "        # letter matches\n",
    "        letter_match : torch.Tensor = self.letter_filter(current_img)\n",
    "        # letter hits total\n",
    "        letter_hits_total = torch.sum(filled_pixels == 0)\n",
    "\n",
    "        \n",
    "\n",
    "        while torch.any(letter_match > self.eps) and letter_hits_total < max_letter_hits_total:\n",
    "            # TODO work on this line\n",
    "            weighted_letter_match = letter_match.mul(torch.abs(self.letter_size_alpha *letter_areas - self.detail_beta * detail_map))\n",
    "\n",
    "            fig, axes = plt.subplots(2, 5, figsize=(12,6))\n",
    "            axes.flat[0].imshow(grad_magnitude.detach()[0][0])\n",
    "            axes.flat[1].imshow(detail_map.detach()[0][0])\n",
    "            axes.flat[2].imshow(letter_match.detach()[0][0])\n",
    "            axes.flat[3].imshow(letter_match.detach()[0][33])\n",
    "            axes.flat[4].imshow(weighted_letter_match.detach()[0][33])\n",
    "            axes.flat[5].imshow(current_img.detach()[0][0])\n",
    "            axes.flat[5].imshow(self.transp_conv(letter_hits).clip(torch.tensor(0.), torch.tensor(1.)).detach()[0][0])\n",
    "\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            indices = torch.argmax(weighted_letter_match.view(B, -1), dim=1, keepdim=True)\n",
    "            tmp_var = indices // (H_letter_hits*W_letter_hits*B)\n",
    "            tmp_val = weighted_letter_match.flatten()[indices]\n",
    "            mask = torch.zeros_like(weighted_letter_match.view(B, -1))\n",
    "            mask = mask.scatter(1, indices, 1)\n",
    "            mask = mask.view(B, self.num_letters, H_letter_hits, W_letter_hits)\n",
    "            # add max letter hit of image of current iteration to all letterhits\n",
    "            letter_hits = letter_hits + mask.mul(letter_match)\n",
    "\n",
    "            # set filled pixels to 0 in filled pixels mask\n",
    "            filled_pixels = (letter_hits > 0).sum(dim=1, keepdim=True) < self.letters_per_pix\n",
    "\n",
    "            # update current image: substract found best letter from input img TODO make this negative?\n",
    "            current_img = torch.clip(input_img - self.transp_conv(letter_hits), torch.tensor(0.), torch.tensor(1.))\n",
    "\n",
    "            # letter matches\n",
    "            letter_match = self.letter_filter(current_img)\n",
    "            # set pixel with reached max letters per pix to zero\n",
    "            letter_match = letter_match.mul(filled_pixels)\n",
    "\n",
    "            # letter hits total\n",
    "            letter_hits_total = torch.sum(filled_pixels == 0)\n",
    "        \n",
    "        return letter_hits, self.transp_conv(letter_hits).clip(torch.tensor(0.), torch.tensor(1.))\n",
    "\n",
    "from data import get_img_transforms_train, get_img_transforms_train_target, BigImagesDataset,  get_img_transforms_test, get_img_transforms_test_target, BigImagesDataModule\n",
    "import config.config as configFile\n",
    "from utils import convert_rgb_tensor_for_plot, convert_gray_tensor_for_plot\n",
    "\n",
    "\n",
    "train_transforms = get_img_transforms_train(224)\n",
    "train_target_transforms = get_img_transforms_train_target(224)\n",
    "ds_train = BigImagesDataset(str(configFile.TRAINING_IMGS_DIR), train_transforms, train_target_transforms)\n",
    "\n",
    "in_img, target, label = ds_train[100]\n",
    "plt.imshow(convert_gray_tensor_for_plot(in_img.unsqueeze(0)).squeeze(0).squeeze(0), cmap=\"gray\")\n",
    "print(ds_train[0][0].shape)\n",
    "print(target.min(), target.max())\n",
    "\n",
    "config = {\n",
    "    \"device\": \"cpu\",\n",
    "    \"letter_conv_k\": 31,\n",
    "    \"letter_conv_stride\": 2,\n",
    "    \"sobel_k\": 3,\n",
    "    \"gauss_sig\": 1,\n",
    "    \"font_path\": str(configFile.FONT_PATH),\n",
    "    \"letters\":  configFile.TYPEWRITER_CONFIG[\"letterList\"],\n",
    "    \"letters_per_pix\": 1,\n",
    "    \"eps\": 0.05,\n",
    "    \"letter_size_weight\": 1.,\n",
    "    \"detail_weight\": 1.2,\n",
    "    \"overlap_gamma\": 1.,\n",
    "}\n",
    "\n",
    "letter_filter = LetterFilter(config)\n",
    "letter_hits, out_img = letter_filter.forward(in_img.unsqueeze(0))\n",
    "\n",
    "plt.imshow(out_img.detach().squeeze(0).squeeze(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"device\": \"cpu\",\n",
    "    \"letter_conv_k\": 31,\n",
    "    \"letter_conv_stride\": 2,\n",
    "    \"sobel_k\": 3,\n",
    "    \"gauss_sig\": 1,\n",
    "    \"font_path\": str(configFile.FONT_PATH),\n",
    "    \"letters\":  configFile.TYPEWRITER_CONFIG[\"letterList\"],\n",
    "    \"letters_per_pix\": 1,\n",
    "    \"eps\": 0.05,\n",
    "    \"letter_size_weight\": 1,\n",
    "    \"detail_weight\": 1,\n",
    "    \"overlap_gamma\": 1,\n",
    "}\n",
    "\n",
    "letter_filter = LetterFilter(config)\n",
    "letter_hits, out_img = letter_filter.forward(in_img.unsqueeze(0))\n",
    "\n",
    "plt.imshow(out_img.detach().squeeze(0).squeeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
